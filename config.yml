controller:
  general:
    cost_function: 'quadratic-boundary-grad' #from 'quadratic-boundary', 'quadratic-boundary-nonconvex', 'default'
  cem:
    SEED: "None"
    dt: 0.02                              # sec
    mpc_horizon: 1.0                      # sec
    cem_outer_it: 5                    #how many outer iterations to use
    cem_rollouts: 2000          #how many rollouts per outer cem iteration
    cem_predictor_type: "EulerTF"               # One of ["Euler", "NeuralNet"]
    CEM_NET_NAME: 'GRU-6IN-32H1-32H2-5OUT-0' # Applies only if predictor_type is NeuralNet
    cem_stdev_min: 0.1
    cem_R: 1
    cem_ccrc_weight: 1
    cem_best_k: 5
    cem_LR: 0.1
  cem-naive-grad:
    SEED: "None"
    dt: 0.02                              # sec
    mpc_horizon: 1.0                      # sec
    cem_outer_it: 5                    #how many outer iterations to use
    cem_rollouts: 2000          #how many rollouts per outer cem iteration
    cem_predictor_type: "EulerTF"               # One of ["Euler", "NeuralNet"]
    CEM_NET_NAME: 'GRU-6IN-32H1-32H2-5OUT-0' # Applies only if predictor_type is NeuralNet
    cem_stdev_min: 0.1
    cem_R: 1
    cem_ccrc_weight: 1
    cem_best_k: 4
    cem_LR: 0.02
    gradmax_clip: 10
  mppi-optimize:
    SEED: "None"
    LR: 0.02
    adam_beta_1: 0.9    #default: 0.9
    adam_beta_2: 0.999  #default: 0.999
    adam_epsilon: 1e-07 #default: 1e-07
    gradmax_clip: 1000
    dt: 0.02                              # sec
    mpc_horizon: 1.0                      # sec
    num_rollouts: 100                     # Number of Monte Carlo samples
    predictor_type: "EulerTF"               # One of ["Euler", "NeuralNet"]
    NET_NAME: 'GRU-6IN-32H1-32H2-5OUT-0'  # Applies only if predictor_type is NeuralNet
    cc_weight: 1.0
    R: 1.0                                # How much to punish Q
    LBD: 100.0                            # Cost parameter lambda
    NU: 1000.0                            # Exploration variance
    SQRTRHOINV: 0.06
    GAMMA: 1.00                           # Future cost discount
    SAMPLING_TYPE: "interpolated"         # One of ["iid", "random_walk", "uniform", "repeated", "interpolated"]
    optim_steps: 40
  dist-adam-resamp:
    resamp_per: 1
    stdev_min: 0.5
    LR: 0.004
    adam_beta_1: 0.3    #default: 0.9
    adam_beta_2: 0.95  #default: 0.999
    adam_epsilon: 1e-07 #default: 1e-07
    cem_best_k: 5
    num_rollouts: 20
    SAMPLING_TYPE: "interpolated" #if interpolated: linear interpolation; else iid
    warmup: False
    interpolation_step: 10
    cem_outer_it: 10
  dist-adam-resamp2:
    SEED: "None"
    dt: 0.02
    mpc_horizon: 1.0
    predictor_type: "EulerTF"               # One of ["Euler", "NeuralNet", "EulerTF"]
    NET_NAME: 'GRU-6IN-32H1-32H2-5OUT-0'  #DOES NOT WORK YET!!! Applies only if predictor_type is NeuralNet
    resamp_per: 1
    sample_stdev: 0.5
    LR: 0.006
    adam_beta_1: 0.9    #default: 0.9
    adam_beta_2: 0.9 #default: 0.999
    adam_epsilon: 1e-07 #default: 1e-07
    opt_keep_k: 1
    num_rollouts: 20
    SAMPLING_TYPE: "interpolated" #if interpolated: linear interpolation; else iid
    warmup: True
    interpolation_step: 10
    outer_its: 20
    gradmax_clip: 1000
  mppi:
    SEED: "None"                            # Seed for rng, for MPPI only, put "None" to set random seed (do it when you generate data for training!)
    dt: 0.02                              # sec
    mpc_horizon: 1.0                      # sec
    num_rollouts: 2000                      # Number of Monte Carlo samples
    update_every: 1                       # Cost weighted update of inputs every ... steps
    predictor_type: "EulerTF"               # One of ["Euler", "NeuralNet"]
    NET_NAME: 'GRU-6IN-32H1-32H2-5OUT-0'  # Applies only if predictor_type is NeuralNet
    dd_weight: 120.0
    ep_weight: 50000.0
    ekp_weight: 0.01
    ekc_weight: 5.0
    cc_weight: 1.0
    ccrc_weight: 1.0
    cost_noise: 0.0                       # Noise on stage cost weights by +/- this value, we usually set 0.5 to explore various controllers while collecting data for training, 0 othewise
    control_noise: 0.0                    # Noise on top of the calculated control input by +/- this value, we usually set 0.5 to explore various controllers while collecting data for training, 0.1 to test an not-ideal case
    R: 1.0                                # How much to punish Q
    LBD: 100.0                            # Cost parameter lambda
    LBD_mc: 10.0
    NU: 1000.0                            # Exploration variance
    NU_mc: 20.0                              # Exploration variance for mathematical correct version
    SQRTRHOINV: [0.02]
    SQRTRHOINV_mc: [0.002]                      # Sampling variance
    GAMMA: 1.00                           # Future cost discount
    SAMPLING_TYPE: "interpolated"         # One of ["iid", "random_walk", "uniform", "repeated", "interpolated"]
    LOGGING: False                        # Collect and show detailed insights into the controller's behavior
    WASH_OUT_LEN: 100                     # Only matters if RNN used as predictor; For how long MPPI should be desactivated (replaced either with LQR or random input) to give memory units time to settle
    CLIP_CONTROL_INPUT: [1.0]            # How to clip control input, symmetric
  custom_mpc_scipy:
    DT: 0.1
    # method: 'L-BFGS-B'
    method: 'SLSQP'
    ftol: 1.0e-8
    mpc_horizon: 10
    # weights
    wr: 0.001  # rterm
    l1: 100.0  # angle_cost
    l1_2: 0.0  # angle_sin_cost
    l2: 0.0  # angleD_cost
    l3: 0.0  # position_cost
    l4: 0.01  # positionD_cost
    m1: 0.0  # angle_sin_cost
    m2: 0.0  # angleD_cost
    m3: 0.0  # position_cost
    m4: 0.0  # positionD_cost
  do_mpc_discrete:
    dt_mpc_simulation: 0.02  # s
    mpc_horizon: 50
  do_mpc:
    dt_mpc_simulation: 0.02  # s
    mpc_horizon: 50
    # Perturbation factors:
    # Change of output from optimal
    p_Q: 0.00
    # Random change of cost function by factor
    p_position: 0.0
    p_positionD: 0.0
    p_angle: 0.0
    # Cost factor
    l_angle: 0.1
    l_position: 1.0
    l_positionD: 0.1
  lqr:
    Q: [10.0, 1.0, 1.0, 1.0]
    R: 10.0
    SEED: 'None'                            # Seed for rng, for lqr only, put "None" to set random seed (do it when you generate data for training!)
    control_noise: 1.0
  pid:
    P_angle: 9.0
    I_angle: 0.0
    D_angle: 0.0
    P_position: 0.1
    I_position: 0.0
    D_position: 0.1
  mpc_opti:
    dt_mpc_simulation: 0.2  # s
    mpc_horizon: 10
  nn_as_mpc_tf:
    net_name: 'Dense-6IN-32H1-32H2-1OUT-0'
    PATH_TO_MODELS: './Controllers/models_for_nn_as_mpc_tf/'
cartpole:
  SEED: 1873  # This is a seed for rng for CartPole instance class only. If "None" random seed based on datetime is used
  PATH_TO_CONTROLLERS: './Controllers/'  # Path where controllers are stored
  PATH_TO_EXPERIMENT_RECORDINGS_DEFAULT: './Experiment_Recordings/'   # Where to save experiment recording per default
  m: 0.087  # mass of pole, kg # Checked by Antonio & Tobi
  M: 0.230  # mass of cart, kg # Checked by Antonio
  L: "0.395/2.0"  # HALF (!!!) length of pend, m # Checked by Antonio & Tobi
  u_max: 2.62  # max force produced by the motor, N # Checked by Marcin
  M_fric: 4.77  # cart friction on track, N/m/s # Checked by Marcin
  J_fric: 2.5e-4  # friction coefficient on angular velocity in pole joint, Nm/rad/s # Checked by Marcin
  v_max: 0.8  # max DC motor speed, m/s, in absense of friction, used for motor back EMF model # TODO: not implemented in model, but needed for MPC
  cart_length: 4.4e-2  # m, checked by Marcin&Asude
  usable_track_length: 44.0e-2  # m, checked by Marcin&Asude
  controlDisturbance: 0.0  # disturbance, as factor of u_max
  controlBias: 0.0  # bias of control input
  g: 9.81  # absolute value of gravity acceleration, m/s^2
  k: "1.0/3.0"  # Dimensionless factor of moment of inertia of the pole with length 2L: I: (1/3)*m*(2L)^2 = (4/3)*m*(L)^2
  latency: 0.0 # s
  noise:
    noise_mode: 'OFF'
    sigma_angle: 0.0  # As measured by Asude
    sigma_position: 0.001
    sigma_angleD: 0.15 # This is much smaller than would result from sigma_angle under assumption of iir filter+derviative calculation; the theoretical value would be 2.28
    sigma_positionD: 0.01

data_generator:
  SEED: 1  # If "None" random seed based on datetime is used